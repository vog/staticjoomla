#!/usr/bin/env python2

'''Staticjoomla - Protect against Joomla security flaws by not running Joomla in public'''

__copyright__ = '''\
Copyright (C) Volker Diels-Grabsch <v@njh.eu>

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
'''

from ConfigParser import ConfigParser
from collections import namedtuple
from errno import EEXIST
from os import makedirs, mkdir, rename, walk
from os.path import abspath, dirname, exists, isdir, join
from re import findall, sub
from shutil import rmtree
from subprocess import PIPE, Popen
from sys import argv, stderr

Config = namedtuple('Config', [
    'offline',
    'schema',
    'host',
    'port',
    'user',
    'password',
    'keep_filenames',
    'own_domains',
    'downloaddir',
    'additionaldir',
    'templatepath',
    'publicdir',
])

Resource = namedtuple('Resource', [
    'path',
    'data',
])

def makedirs_exist_ok(name, mode):
    # Portability with Python 2, see http://stackoverflow.com/a/600612
    try:
        makedirs(name, mode)
    except OSError as e:
        if e.errno == EEXIST and isdir(name):
            pass
        else:
            raise

def almost_atomic_directory_replace(dirpath, keep_prev):
    dirpath_prev = '{dirpath}.prev'.format(**locals())
    dirpath_next = '{dirpath}.next'.format(**locals())
    if exists(dirpath_next):
        rmtree(dirpath_next)
    mkdir(dirpath_next)
    yield dirpath_next
    if exists(dirpath_prev):
        rmtree(dirpath_prev)
    if exists(dirpath):
        rename(dirpath, dirpath_prev)
    rename(dirpath_next, dirpath)
    if not keep_prev:
        rmtree(dirpath_prev)

def get_internal_url(schema, host, port):
    if schema == 'https' and port == '443':
        return '{}://{}/'.format(schema, host)
    if schema == 'http' and port == '80':
        return '{}://{}/'.format(schema, host)
    return '{}://{}:{}/'.format(schema, host, port)

def get_rel_path(path, basepath):
    prefix = basepath + '/'
    if not path.startswith(prefix):
        raise ValueError('Path {!r} does not start with prefix {!r}'.format(path, prefix))
    return path[len(prefix):]

def get_resources(resourcesdir):
    resources = []
    for dirpath, dirnames, filenames in walk(resourcesdir):
        for filename in filenames:
            filepath = join(dirpath, filename)
            with open(filepath, 'rb') as f:
                data = f.read()
            resources.append(
                Resource(
                    path=get_rel_path(filepath, resourcesdir),
                    data=data,
                ),
            )
    return resources

def download_website(downloaddir, schema, host, port, user, password):
    for downloaddir_next in almost_atomic_directory_replace(downloaddir, keep_prev=True):
        args = [
            'wget',
            '-rEpH',
            '-nH',
            '-l',
            'inf',
            '-D',
            host,
            '-nv',
            '--http-user={}'.format(user),
            '--http-password={}'.format(password),
            get_internal_url(schema, host, port),
        ]
        proc = Popen(args, cwd=downloaddir_next, stdin=PIPE, stdout=PIPE, stderr=PIPE)
        output, error = proc.communicate()
        if proc.returncode != 0:
            raise ValueError('Failed to download website:\n{output}\n{error}\n\nFailed to download website! Return code: {proc.returncode}\n'.format(**locals()))

def has_binary_suffix(path):
    binary_suffixes = [
        '.JPG',
        '.eot',
        '.gif',
        '.ico',
        '.jpeg',
        '.jpg',
        '.js',
        '.pdf',
        '.png',
        '.swf',
        '.ttf',
        '.woff',
    ]
    text_suffixes = [
        '.css',
        '.htm',
        '.html',
        '.svg',
        '.txt',
    ]
    if any(path.endswith(binary_suffix) for binary_suffix in binary_suffixes):
        return True
    if any(path.endswith(text_suffix) for text_suffix in text_suffixes):
        return False
    raise ValueError('Unknown suffix of path: {!r}'.format(path))

def fix_line_endings(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    data = resource.data
    data = data.replace('\r\n', '\n')
    data = data.replace('\r', '\n')
    return data

def stabilize_hidden_form_field_names(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    data = resource.data
    data = sub(
        r'<input type="hidden" name="[0-9a-f]{32}" value="1" />',
        '<input type="hidden" name="e7db122ac127e2f53c2595250560f9f6" value="1" />',
        data,
    )
    data = sub(
        r'<input type="hidden" name="return" value="[^"]+" />',
        '<input type="hidden" name="return" value="" />',
        data,
    )
    return data

def replace_all(s, replacements):
    result = s
    for src, dest in replacements:
        result = result.replace(src, dest)
    return result

def without_duplicates_keep_order(iterable):
    s = set()
    result = []
    for e in iterable:
        if not e in s:
            s.add(e)
            result.append(e)
    return result

def stabilize_email_obfuscation_ids(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    new_offset = 89677
    cloak_numbers_with_duplicates = findall(r'cloak([0-9]+)', resource.data)
    cloak_numbers = without_duplicates_keep_order(cloak_numbers_with_duplicates)
    prefixes = ['cloak', 'addy', 'addy_text']
    replacements = [
        ('{}{}'.format(prefix, cloak_number), '{}{}'.format(prefix, new_offset + i))
        for i, cloak_number in enumerate(cloak_numbers)
        for prefix in prefixes
    ]
    return replace_all(resource.data, replacements)

def remove_base_href(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    return sub(r'[\t ]*<base href="[^"]*"[\t ]*/>\n', '', resource.data)

def remove_author_tags(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    return sub(r'[\t ]*<meta name="author" content="[^"]+" />\n', '', resource.data)

def remove_duplicate_jcaption(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    return sub(
        r'''(jQuery\(window\).on\('load',  function\(\) \{\n\s+new JCaption\('img.caption'\);\n\s+\}\);\n){2,}''',
        r'\1',
        resource.data,
    )

def remove_link_rel_canonical(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    return sub(r'[\t ]*<link href="[^"]+" rel="canonical" />\n', '', resource.data)

def remove_link_rel_search(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    return sub(r'[\t ]*<link href="[^"]+" rel="search" title="[^"]+" type="[^"]+" />\n', '', resource.data)

def remove_noscript_tag(resource):
    if has_binary_suffix(resource.path):
        return resource.data
    return sub(r'<noscript>.*?</noscript>', '', resource.data)

def fix_links(schema, host, port, own_domains):
    def f(resource):
        if has_binary_suffix(resource.path):
            return resource.data
        internal_prefix = get_internal_url(schema, host, port)
        relative_prefix = '../' * resource.path.count('/')
        data = resource.data
        data = data.replace(internal_prefix, relative_prefix)
        for own_domain in own_domains:
            data = data.replace('http://{}/'.format(own_domain), relative_prefix)
            data = data.replace('https://{}/'.format(own_domain), relative_prefix)
            data = data.replace('//{}/'.format(own_domain), relative_prefix)
        def replace_href(m):
            # Replace "/path/to/site" but not "//HOST/path/to/site" or "http://HOST/path/to/site" or "path/to/site"
            href = m.group(1)
            if not href.startswith('/'):
                return 'href="{}"'.format(href)
            if href.startswith('//'):
                return 'href="{}"'.format(href)
            return 'href="{}{}"'.format(relative_prefix, href[len('/'):])
        data = sub(r'href="([^"]*)"', replace_href, data)
        return data
    return f

def resources_map_data(resources, f):
    return [
        Resource(path=r.path, data=f(r))
        for r in resources
    ]

def resources_map_path(resources, f):
    return [
        Resource(path=f(r.path), data=r.data)
        for r in resources
    ]

def resources_filter_path(resources, f):
    return [r for r in resources if f(r.path)]

def html_files_to_directories(keep_filenames):
    def f(path):
        for prefix in keep_filenames:
            if path.startswith(prefix):
                return path
        if path == 'index.html':
            return path
        html_suffix = '.html'
        if not path.endswith(html_suffix):
            return path
        return path[:-len(html_suffix)] + '/index.html'
    return f

def no_question_mark(path):
    return '?' not in path

def fix_dot_number_files(path):
    '''Fix paths such as "path/to/somesite.1.html" to "path/to/somesite.html".'''
    return path.replace('.1.', '.')

def cleanup_resources(raw_resources, schema, host, port, keep_filenames, own_domains):
    r = raw_resources
    r = resources_filter_path(r, no_question_mark)
    r = resources_map_path(r, fix_dot_number_files)
    r = resources_map_path(r, html_files_to_directories(keep_filenames))
    r = resources_map_data(r, fix_line_endings)
    r = resources_map_data(r, stabilize_hidden_form_field_names)
    r = resources_map_data(r, stabilize_email_obfuscation_ids)
    r = resources_map_data(r, remove_base_href)
    r = resources_map_data(r, remove_author_tags)
    r = resources_map_data(r, remove_duplicate_jcaption)
    r = resources_map_data(r, remove_link_rel_canonical)
    r = resources_map_data(r, remove_link_rel_search)
    r = resources_map_data(r, remove_noscript_tag)
    r = resources_map_data(r, fix_links(schema, host, port, own_domains))
    return r

def apply_template_to_resource(resource, templatepath):
    suffix = '.content'
    title_prefix = '= '
    if not resource.path.endswith(suffix):
        return resource
    with open(templatepath, 'rb') as f:
        template = f.read()
    data_normalized = resource.data.replace('\r\n', '\n').replace('\r', '\n')
    if not '\n' in data_normalized:
        raise ValueError('Missing newline in resource {!r}'.format(resource.path))
    firstline, content = data_normalized.split('\n', 1)
    if not firstline.startswith(title_prefix):
        raise ValueError('Invalid first (title) line in resource {!r}: {!r}'.format(resource.path, firstline))
    title = firstline[len(title_prefix):]
    return Resource(
        path='{}.html'.format(resource.path[:-len(suffix)]),
        data=template.replace('@!title!@', title).replace('@!content!@', content),
    )

def apply_template(raw_resources, templatepath):
    return [
        apply_template_to_resource(resource, templatepath)
        for resource in raw_resources
    ]

def check_duplicate_paths(paths):
    seen_paths = set()
    for p in paths:
        if p in seen_paths:
            raise ValueError('Duplicate path: {!r}'.format(p))
        seen_paths.add(p)

def check_directory_paths(paths):
    for p in paths:
        for q in paths:
            if p.startswith('{}/'.format(q)):
                raise ValueError('Path {!r} uses existing path {!r} as directory'.format(p, q))

def check_base_href(resources):
    for r in resources:
        if '<base' in r.data:
            raise ValueError('Resource {!r} contains <base> element'.format(r.path))

def check_internal_host(host, resources):
    for r in resources:
        if host in r.data:
            raise ValueError('Resource {!r} contains internal host name {!r}'.format(r.path, host))

def check_linked_domains(host, resources):
    internal_domains = [
        host,
        '127.0.0.1',
        'localhost',
    ]
    for r in resources:
        if has_binary_suffix(r.path):
            continue
        linked_domains = findall(r'//([a-z0-9.][a-z0-9.-]*)', r.data)
        for domain in linked_domains:
            if domain in internal_domains:
                raise ValueError('Resource {!r} contains link to internal domain {!r}'.format(r.path, domain))

def check_resources(resources, host):
    paths = [r.path for r in resources]
    check_duplicate_paths(paths)
    check_directory_paths(paths)
    check_base_href(resources)
    check_internal_host(host, resources)
    check_linked_domains(host, resources)

def write_resources(publicdir, resources):
    for publicdir_next in almost_atomic_directory_replace(publicdir, keep_prev=True):
        for r in resources:
            outputpath = join(publicdir_next, r.path)
            makedirs_exist_ok(dirname(outputpath), 0700)
            with open(outputpath, 'wb') as f:
                f.write(r.data)

def get_config(config_filepath):
    cp = ConfigParser()
    cp.read(config_filepath)
    datadir = abspath(join(dirname(config_filepath), cp.get('config', 'datadir')))
    return Config(
        offline={'yes': True, 'no': False}[cp.get('config', 'offline')],
        schema=cp.get('config', 'schema'),
        host=cp.get('config', 'host'),
        port=cp.get('config', 'port'),
        user=cp.get('config', 'user'),
        password=cp.get('config', 'password'),
        keep_filenames=cp.get('config', 'keep_filenames').split(),
        own_domains=cp.get('config', 'own_domains').split(),
        downloaddir=join(datadir, 'download'),
        additionaldir=join(datadir, 'additional/public'),
        templatepath=join(datadir, 'additional/template.html'),
        publicdir=join(datadir, 'public'),
    )

def run(config_filepath):
    c = get_config(config_filepath)
    if not c.offline:
        download_website(c.downloaddir, c.schema, c.host, c.port, c.user, c.password)
    dl_raw_resources = get_resources(c.downloaddir)
    dl_resources = cleanup_resources(dl_raw_resources, c.schema, c.host, c.port, c.keep_filenames, c.own_domains)
    additional_raw_resources = get_resources(c.additionaldir)
    additional_resources = apply_template(additional_raw_resources, c.templatepath)
    resources = dl_resources + additional_resources
    check_resources(resources, c.host)
    write_resources(c.publicdir, resources)

def fetch(config_filepath):
    run(config_filepath)

def usage():
    stderr.write(
        __doc__ + '\n'
        '\n'
        'Usage:\n'
        '\n'
        '    staticjoomla fetch   /PATH/TO/staticjoomla.ini\n'
        '\n'
    )
    exit(1)

def main():
    try:
        command = argv[1]
    except IndexError:
        return usage()
    command_args = argv[2:]
    if command == 'fetch' and len(command_args) == 1:
        return fetch(*command_args)
    return usage()

main()
